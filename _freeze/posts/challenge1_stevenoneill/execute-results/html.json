{
  "hash": "0f005f74f6239b5e63787bf3397b54e0",
  "result": {
    "markdown": "---\ntitle: \"Challenge 1\"\nauthor: \"Steve O'Neill\"\ndesription: \"Reading in data and creating a post\"\ndate: \"08/15/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_1\n  - tidyverse\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to\n\n1)  read in a dataset, and\n\n2)  describe the dataset using both words and any supporting information (e.g., tables, etc)\n\n## Read in the Data\n\nRead in one (or more) of the following data sets, using the correct R package and command.\n\n-   railroad_2012_clean_county.csv ⭐\n-   birds.csv ⭐⭐\n-   FAOstat\\*.csv ⭐⭐\n-   wild_bird_data.xlsx ⭐⭐⭐\n-   **StateCounty2012.xlsx** ⭐⭐⭐⭐\n\nFind the `_data` folder, located inside the `posts` folder. Then you can read in the data, using either one of the `readr` standard tidy read commands, or a specialized package such as `readxl`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Importing the dataset, and removing the first two rows of unhelpful data:\ndf1 <- read_xls(\"_data/StateCounty2012.xls\", skip = 2)\n\n#I really tried, but I couldn't get the relative paths to work :( \n# getwd() returned \"C:/Users/stevenoneill/Downloads/dacss601_august2022\"\n#df1 <- read_xls(\"./posts/_data/StateCounty2012.xls\", skip = 2)\n#df1 <- read_xls(\"_data/StateCounty2012.xls\", skip = 2)\n\n#I used my Downloads folder because I would rather not exempt my Documents folder from OneDrive. Willing to die on this hill.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#First, removing unused columns\ndf2 <- df1 %>% select(STATE,COUNTY,TOTAL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Second, removing unhelpful pre-calculated totals:\ndf3=df2[grepl(\"^[a-zA-Z][a-zA-Z]$\",df2$STATE),]\n```\n:::\n\n\n*Add any comments or documentation as needed. More challenging data sets may require additional code chunks and documentation.*\n\n## Describe the data\n\n*Using a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data).*\n\nThis data describes railroad employment in U.S. states and territories. In this instance, the original 'cases' are the *counties* and the original 'variables' are their parent states and the total number of persons employed in the railroad industry in those counties.\n\nYou may notice the data contains the uncommon state codes \"AE\" and \"AP\", as well as the recurring \"APO\" county name. These represent [military addresses](https://pe.usps.com/text/pub28/28c2_010.htm):\n\n| State Code | Location                            |\n|------------|-------------------------------------|\n| AE         | Europe, Middle East, Africa, Canada |\n| AP         | Asia Pacific                        |\n| AA         | Americas (excluding Canada)         |\n\n'APO' refers to \"Army Post Office\".\n\nI have calculated some basic statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Group by state, but first, add the largest county to the dataframe\nby_state <- df3 %>% group_by(STATE) %>% \n    mutate(largest.county.name = COUNTY[which.max(TOTAL)]) %>% \n      mutate(smallest.county.name = COUNTY[which.min(TOTAL)])\n\n#Group by state, then summarize the total of all county employees, per-state:\nby_state <- by_state %>% summarise(\n  total.state.employees = sum(TOTAL),\n  median.county.employees = median(TOTAL),\n  smallest.county = min(TOTAL),\n  smallest.county.name = first(smallest.county.name),\n  largest.county = max(TOTAL),\n  largest.county.name = first(largest.county.name),\n  standard.dev = sd(TOTAL)\n)\n\nby_state\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 53 × 8\n   STATE total.state.employees median.…¹ small…² small…³ large…⁴ large…⁵ stand…⁶\n   <chr>                 <dbl>     <dbl>   <dbl> <chr>     <dbl> <chr>     <dbl>\n 1 AE                        2       2         2 APO           2 APO        NA  \n 2 AK                      103       2.5       1 SITKA        88 SKAGWA…    34.8\n 3 AL                     4257      26         1 BARBOUR     990 JEFFER…   130. \n 4 AP                        1       1         1 APO           1 APO        NA  \n 5 AR                     3871      16.5       1 NEWTON      972 PULASKI   131. \n 6 AZ                     3153      94         3 GREENL…     749 PIMA      228. \n 7 CA                    13137      61         1 MONO       2888 SAN BE…   549. \n 8 CO                     3650      10         1 BENT        553 ADAMS     128. \n 9 CT                     2592     125        26 TOLLAND    1561 NEW HA…   520. \n10 DC                      279     279       279 WASHIN…     279 WASHIN…    NA  \n# … with 43 more rows, and abbreviated variable names ¹​median.county.employees,\n#   ²​smallest.county, ³​smallest.county.name, ⁴​largest.county,\n#   ⁵​largest.county.name, ⁶​standard.dev\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nA few things stand out:\n\n-   Texas has the largest amount of railroad employees combined, at 19,839.\n-   However, Illinois has the largest single county of railroad employees in Cook County, at 8207. That's almost double the next-largest in Tarrant, TX.\n-   Illinois also possesses one of the smallest counties by the same metric - Hardin County, with only one employee. It has the highest standard deviation among in-state counties.\n\nLooking forward to the next steps in analysis.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}